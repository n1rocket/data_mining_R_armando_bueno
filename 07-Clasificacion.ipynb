{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística\n",
    "\n",
    "En lugar de realizar una predicción de un valor queremos hacer un clasificador.\n",
    "\n",
    "\n",
    "Si lo que tenemos son dos grupos y queremos realizar una clasificación, tenemos que realizar ciertas modificaciones a la regresión lineal.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "La fórmula de la regresión lineal es:\n",
    "\\\\[\n",
    "\\hat{Y}=\\beta_1 X_1+\\beta_2 X_2+\\cdots +\\beta_p X_p = \\sum \\beta_k X_k\n",
    "\\\\]\n",
    "\n",
    "Podemos tratar de asignar una probabilidad. Pero hay un problema porque esta regresión va entre 0 y 1.\n",
    "\n",
    "\n",
    "Por ejemplo: Trabajamos en un RADAR y queremos saber si hemos detectado un avión a es solo ruido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/radar.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height=4,repr.plot.width=8,repr.plot.res = 300)\n",
    "\n",
    "library(ggplot2)\n",
    "\n",
    "radar<-read.csv(\"data/radar-lite.csv\", stringsAsFactors = T)\n",
    "summary(radar)\n",
    "ggplot(radar,aes(x=distancia,y=potencia,color=tipo))+geom_point(size=3)+\n",
    " ylab(\"potencia [mW]\")+xlab(\"distancia [Km]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar$tipo<-relevel(radar$tipo,ref=\"ruido\")\n",
    "summary(radar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer una clasificación con un modelo lineal donde creamos una nueva columna *tipo.n* y le asignamos:\n",
    "* avión  = 1\n",
    "* ruido = 0\n",
    "\n",
    "Utilizamos un modelo lineal tal que:\n",
    "\\\\[\n",
    "  tipo.n = \\beta_0+\\beta_1·distancia+\\beta_2·potencia\n",
    "\\\\]\n",
    "\n",
    "Entonces:\n",
    "* si tipo.n >= 0.5 es un avión\n",
    "* si tipo.n <  0.5 es ruido\n",
    "\n",
    "La recta que marcará el umbral será:\n",
    "\\\\[\n",
    "\\begin{split}    \n",
    "  0 &= \\beta_0+\\beta_1·distancia+\\beta_2·potencia \\\\\n",
    "  -\\beta_2 potencia &= \\beta_0+\\beta_1·distancia - 0.5\\\\\n",
    "  potencia &= \\frac{0.5-\\beta_0}{\\beta_2}-\\frac{\\beta_1}{\\beta_2}·distancia\n",
    "\\end{split}  \n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "set.seed(2)\n",
    "\n",
    "radar$tipo.n[radar$tipo==\"avion\"] <- 1\n",
    "radar$tipo.n[radar$tipo==\"ruido\" ]<- 0\n",
    "\n",
    "\n",
    "itrain<-sample(1:nrow(radar),round(nrow(radar)*0.7))\n",
    "radar.train<- radar[itrain,]\n",
    "radar.test <- radar[-itrain,]\n",
    "\n",
    "\n",
    "modellm<-lm(data=radar.train,formula=tipo.n~distancia+potencia)\n",
    "beta<-modellm$coefficients\n",
    "\n",
    "ggplot(radar.train,aes(x=distancia,y=potencia,color=tipo))+geom_point(size=3)+\n",
    " geom_abline(intercept = (0.5-beta[1])/beta[3],slope = -beta[2]/beta[3], color=\"red\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero esto no es del todo correcto porque los datos **NO** siguen una distribución gaussiana. Siguen una distribución **binomial** con dos posibles valores 0 o 1.\n",
    "\n",
    "La distribución binomial es una generalización de la distribución de Bernoulli para $n$ sucesos independientes, cada uno de los cuales tiene dos posibles resultados Si/No con probabilidad $p$.\n",
    "\n",
    "**Ejemplo:** Tiramos al aire 3 monedas y mirarmos cual es la probabilidad de que 2 salgan cara.\n",
    "\n",
    "Variables que definen la distribución:\n",
    "* p - probabilidad de éxito de un caso individual\n",
    "* n - número de eventos totales que se desean medir\n",
    "* k - número de eventos que ha salido SI.\n",
    "\n",
    "Estimadores **media** ($\\mu$) y **varianza** ($\\sigma^2$):\n",
    "\\\\[\n",
    "\\mu=n·p \\qquad\n",
    "\\sigma^2=n·p·(1-p)\n",
    "\\\\]\n",
    "\n",
    "Si tenemos $n$ sucesos independientes que siguen una distribución de Bernoulli, ¿cual es la probabilidad de que $k$ sucesos sean positivos?. \n",
    "Si sabemos que la probabilidad de un suceso ($k=1$) que sigue una distribución Bernoulli viene dada por la función de distribución:\n",
    "\\\\[\n",
    "Pr_{Bernoulli}(X=k)=p^k(1-p)^{n-k} \\qquad k \\in \\left\\{0,1 \\right\\}.\n",
    "\\\\]\n",
    "\n",
    "Al tener $k$ sucesos donde $k \\in \\left\\{0,1,2,...,n \\right\\}$, la función será la de Bernoulli multiplicada por el coeficiente binomial que acabamos de ver:\n",
    "\\\\[\n",
    "Pr(X=k)=\\binom{n}{k}p^k(1-p)^{n-k}\n",
    "\\\\]\n",
    "La función acumulativa será:\n",
    "\\\\[\n",
    "Pr(X \\leq k)= \\sum_{i=0}^{k-1} \\binom{n}{k}p^k(1-p)^{n-k}\n",
    "\\\\]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### función de enlace (link function)\n",
    "\n",
    "Para pasar del dominio de números reales $(-\\infty,\\infty)$ al de probabilidades $[0,1]$ a vamos a utilizar la **función logística**:\n",
    "\\\\[\n",
    "p = h(x)=  \\frac{1}{1+e^{-x}}\n",
    "\\\\]\n",
    "Su inversa se conoce como la función **logit**:\n",
    "\\\\[\n",
    "h^{-1}(p) = log \\left( \\frac{p}{1-p} \\right)\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x<-seq(-10,10,length.out = 100)\n",
    "y<-1/(1+exp(-x))\n",
    "plot(x,y,t=\"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, cuando estemos trabajando con una **distribución binomial** un modelo lineal del tipo:\n",
    "\\\\[\n",
    "y = \\beta \\vec{x}+\\beta_0\n",
    "\\\\]\n",
    "será:\n",
    "\\\\[\n",
    "y = p(x) = \\frac{1}{1+e^{-\\beta \\vec{x}-\\beta_0}} \n",
    "\\\\]\n",
    "Ahora $p(x)$ es una función que muestra valores en el rango $[0,1]$, puede ser considerada como una probabilidad.\n",
    "\n",
    "Y tenemos el siguiente clasificador:\n",
    "* Seleccionamos clase 1 si p(x)>=0.5\n",
    "* Seleccionamos clase 0 si p(x)< 0.5\n",
    "\n",
    "\n",
    "\n",
    "Es decir, tenemos una probabilidad, su valor está en el rango $[0,1]$:\n",
    "\\\\[\n",
    "    p = \\frac{1}{1-e^{-\\hat{Y}}}= \\frac{1}{1-e^{-(\\beta_1 X_1+\\beta_2 X_2+\\cdots +\\beta_p X_p)}}   \n",
    "\\\\]\n",
    "\n",
    "Definimos la razón de monomios (Odds ratio) como el cociente entre dos probabilidades, su valor está en el rango $[0,\\infty]$:\n",
    "\\\\[\n",
    "Odds=\\frac{p(x)}{1-p(x)} = \\frac{\\frac{1}{1+e^{-\\beta \\vec{x}-\\beta_0}}}{1-\\frac{1}{1+e^{-\\beta \\vec{x}-\\beta_0}} }\n",
    "\\\\]\n",
    "\\\\[\n",
    "Odds=\\frac{p(x)}{1-p(x)} = \\frac{1}{1+e^{-\\beta \\vec{x}-\\beta_0}-1} \n",
    "\\\\]\n",
    "\\\\[\n",
    "Odds=\\frac{p(x)}{1-p(x)} = e^{\\beta \\vec{x}+\\beta_0}\n",
    "\\\\]\n",
    "\n",
    "\n",
    "\\\\[\n",
    " Odds = \\frac{p}{1-p}=\\frac{\\frac{1}{1-e^{-(\\beta_1 X_1+\\beta_2 X_2+\\cdots +\\beta_p X_p)}}}{\\frac{e^{-(\\beta_1 X_1+\\beta_2 X_2+\\cdots +\\beta_p X_p)}}{1-e^{-(\\beta_1 X_1+\\beta_2 X_2+\\cdots +\\beta_p X_p)}}}=e^{(\\beta_1 X_1+\\beta_2 X_2+\\cdots +\\beta_p X_p)}\n",
    "\\\\]\n",
    "\n",
    "Si aplicamos el logaritmo a la razón de monomios tenemos un valor que está en el rango $[-\\infty,\\infty]$:\n",
    "\\\\[\n",
    " log(Odds)= log \\left(\\frac{p}{1-p} \\right) = \\beta_1 X_1+\\beta_2 X_2+\\cdots +\\beta_p X_p\n",
    "\\\\]\n",
    "\n",
    "La función de coste que vamos a tratar de minimizar será:\n",
    "\\\\[\n",
    "\\begin{split}\n",
    "Cost(p(x),y) &= {1 \\over n} \\sum_{i=0}^n{(y-\\hat{y})^2}\\\\\n",
    "Cost(p(x),y) &= {1 \\over n} \\sum_{i=0}^n{(y-p(x))^2}\n",
    "\\end{split}\n",
    "\\\\]\n",
    "Que transformaremos en:\n",
    "\\\\[\n",
    "Cost(p(x),y) = -y ·log(p(x))-(1-y)·log(1-p(x))\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(radar.train)\n",
    "summary(radar.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model<-glm(data=radar.train,formula=tipo~distancia+potencia,family=binomial(link='logit'))\n",
    "\n",
    "betalg<-model$coefficients\n",
    "\n",
    "ggplot(radar.train,aes(x=distancia,y=potencia,color=tipo))+geom_point(size=3)+\n",
    " geom_abline(intercept = (0.5-beta[1])/beta[3],slope = -beta[2]/beta[3], color=\"red\" )    +\n",
    " geom_abline(intercept = -betalg[1]/betalg[3],slope = -betalg[2]/betalg[3], color=\"blue\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida del modelo es log(odds):\n",
    "\\\\[\n",
    " y = log(Odds) = \\beta_1 X_1+\\beta_2 X_2+\\cdots +\\beta_p X_p\n",
    "\\\\]\n",
    "Si queremos la probabilidad tenemos que aplicar un poco de cálculo:\n",
    "\\\\[\n",
    " Odds = \\frac{p}{1-p}\n",
    "\\\\]\n",
    "\\\\[\n",
    " y = log(Odds) = log \\left( \\frac{p}{1-p} \\right) \\\\\n",
    " e^y = \\left( \\frac{p}{1-p} \\right) \\\\\n",
    " e^y·(1-p) = p \\\\\n",
    " e^y = p+p·e^y \\\\\n",
    " e^y = p·(1+e^y) \\\\\n",
    " p=\\frac{e^y}{1+e^y}\n",
    "\\\\]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out<-radar.test\n",
    "out[\"y\"]<-predict(model,radar.test)\n",
    "\n",
    "ggplot(out,aes(x=y,color=tipo))+geom_histogram(aes(fill=tipo))+xlab(\"odds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out<-radar.test\n",
    "out[\"y\"]<-predict(model,radar.test)\n",
    "out[\"probs\"]<-exp(out[\"y\"])/(1+exp(out[\"y\"]))\n",
    "out[\"probs\"]<-1/(1+exp(-out[\"y\"]))\n",
    "\n",
    "ggplot(out,aes(x=probs,color=tipo))+geom_density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[\"probs\"]<-predict(model,radar.test,type=\"response\")\n",
    "\n",
    "ggplot(out,aes(x=probs,color=tipo))+geom_density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusión\n",
    "\n",
    "Aqui lo que tenemos es un clasificador con dos hipótesis $H_0$ (hipótesis negativa) y $H_1$ (hipótesis positiva). \n",
    "Si nuestro test estadístico dice que la hipótesis $H_1$ es cierta pero en realidad la que es cierta es la hipótesis $H_0$ estaremos cometiendo un error.\n",
    "El tipo de error depende de si nos hemos equivocado prediciendo $H_0$ o $H_1$.\n",
    "\n",
    "|.|Elegimos $H_0$|Elegimos $H_1$|\n",
    "|-|-|-|\n",
    "|$H_0$ cierta| No hay error |Error tipo I, falso positivo|\n",
    "|$H_1$ cierta| Error tipo II, falso negativo| No hay error |\n",
    "\n",
    "\n",
    "La matriz de confusión lo que hace es contar el número de ocurrencias que ha habido en cada celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M<-matrix(rep(0,4),ncol = 2)\n",
    "umbral <- 2\n",
    "radar_pred  <- predict(model,radar.test)\n",
    "y_est=factor(ifelse(radar_pred < umbral,0,1),labels=c(\"ruido\",\"avion\"))\n",
    "\n",
    "\n",
    "M = table(real=radar.test$tipo,elegimos=y_est)\n",
    "M\n",
    "\n",
    "ggplot(radar.test,aes(x=distancia,y=potencia,color=tipo))+geom_point(size=3)+\n",
    " geom_abline(intercept = (-betalg[1])/betalg[3],slope = -betalg[2]/betalg[3], color=\"blue\", linetype=\"dashed\")+\n",
    " geom_abline(intercept = (umbral-betalg[1])/betalg[3],slope = -betalg[2]/betalg[3], color=\"blue\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas de calidad\n",
    "\n",
    "Imaginemos que tenemos la siguiente matriz de confusión:\n",
    "\n",
    "|.|Predecimos condición negativa|Predecimos condición positiva|\n",
    "|-|-|-|\n",
    "|Condición negativa| $M_{11}$ | $M_{12}$|\n",
    "|Condición positiva| $M_{21}$ | $M_{22}$ |\n",
    "\n",
    "**Precisión** : $\\frac{M_{22}}{M_{12}+M_{22}}$. Cuantos aciertos tengo del total de predicciones. Nos habla de **calidad**.\n",
    "\n",
    "**Exhaustividad** (recall, true positive rate): $\\frac{M_{22}}{M_{21}+M_{22}}$. Que ratio de los aciertos positivos soy capaz de encontrar. Nos habla de **cantidad** de encuentros.\n",
    "\n",
    "**Exactitud** (Accuracy): $\\frac{M_{11}+M_{22}}{M_{11}+M_{12}+M_{21}+M_{22}}$: Cuantas predicciones correctas he hecho.\n",
    "\n",
    "**Valor-F**: $F_\\beta=(1+\\beta^2)\\frac{Precisión·Exhaustividad}{\\beta^2·Precisión+Exhaustividad}$\n",
    "\n",
    "**Probabilidad de falso positivo** (false positive rate): $\\frac{M_{12}}{M_{12}+M_{11}}$. Cuantos positivos **erróneos** he detectado de todos los negativos que hay.\n",
    "\n",
    "A veces la matriz de confusión se muestra cambiada, de hecho Python lo hace así, intercambia las filas y las columnas. Más información aquí:\n",
    "https://towardsdatascience.com/the-two-variations-of-confusion-matrix-get-confused-never-again-8d4fb00df308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore<-function(M,beta){\n",
    "    pr=M[1,1]/(M[1,2]+M[1,1])\n",
    "    rc=M[1,1]/(M[2,1]+M[1,1])\n",
    "    (1+beta^2)*pr*rc/(beta^2*pr+rc)\n",
    "}\n",
    "\n",
    "paste(\"Precision:\",M[2,2]/(M[1,2]+M[2,2]))\n",
    "paste(\"Recall, true positive rate:\",   M[2,2]/(M[2,1]+M[2,2]))\n",
    "paste(\"False positive rate:\",   M[1,2]/(M[1,2]+M[1,1]))\n",
    "paste(\"Accuracy:\", (M[1,1]+M[2,2])/(M[1,1]+M[1,2]+M[2,1]+M[2,2]))\n",
    "paste(\"F0.5-score\",fscore(M,0.5))\n",
    "paste(\"F1-score\",fscore(M,1))\n",
    "paste(\"F2-score\",fscore(M,beta=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva ROC\n",
    "\n",
    "La curva ROC fue comenzada a usar durante la segunda guerra mundial para el análisis de las señales de radar. Después del ataque de Pearl Harbor en 1941, la armada de EEUU comenzó un programa de investigación para aumentar la predicción de los radares a la hora de detectar aviones japoneses. Para ello midieron la habiliad de un radar de detectar esas señales, esa medida la llamaron \"Receiver Operating Characteristic\".\n",
    "\n",
    "Se utiliza para ver la calidad de un detector, un clasificador binario capaz de detectar un elemento.\n",
    "Se hace un barrido por todos los umbrales y se mide el valor de positivo verdadero en función de falso positivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral<- -10\n",
    "radar_pred  <-predict(model,radar.test)\n",
    "\n",
    "df_preds<-data.frame(pred=radar_pred,\n",
    "                     tipo_pred=factor(ifelse(radar_pred < umbral,0,1),labels=c(\"ruido\",\"avion\")),\n",
    "                     tipo_real=radar.test$tipo)\n",
    "df_preds<-df_preds[order(df_preds$pred, decreasing=FALSE),]\n",
    "\n",
    "M<-table(df_preds$tipo_real,df_preds$tipo_pred)\n",
    " #table(real=radar.test$tipo,elegimos=y_est)\n",
    "\n",
    "#Recall, Exhaustividad, Tasa Verdadero positivo\n",
    "truePositive<-M[2,2]/(M[2,2]+M[2,1]) \n",
    "\n",
    "#Tasa Falso positivo\n",
    "falsePositive<-M[1,2]/(M[1,2]+M[1,1])\n",
    "paste(\"tp:\",truePositive,\"  fp:\",falsePositive)\n",
    "M\n",
    "\n",
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calctp_fp<-function(y_predict,y_real,th){\n",
    "    y_est<-ifelse(y_predict<th,0,1)\n",
    "\n",
    "    M<-table(y_real,y_est)\n",
    "    #print(M)\n",
    "    if (ncol(M)==2 && nrow(M)==2){\n",
    "        truePositive<-M[2,2]/(M[2,2]+M[2,1])                     \n",
    "        falsePositive<-M[1,2]/(M[1,2]+M[1,1])\n",
    "        c(tp=truePositive,fp=falsePositive)\n",
    "    }else{\n",
    "        c(tp=NA,fp=NA)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calctp_fp(df_preds$pred,df_preds$tipo_real,th=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfROC<-data.frame(th=unique(df_preds$pred),tp=NA,fp=NA,model=\"model1\")\n",
    "\n",
    "#for (th in seq(min(df_preds$pred),max(df_preds$pred),length.out=10)){\n",
    "#    calctp_fp(df_preds$pred,df_preds$tipo_real,th=th)\n",
    "#}\n",
    "for (i in 1:nrow(dfROC)){\n",
    "    v<-calctp_fp(df_preds$pred,df_preds$tipo_real,th=dfROC$th[i])\n",
    "    dfROC$tp[i]<-v[\"tp\"]\n",
    "    dfROC$fp[i]<-v[\"fp\"]\n",
    "}\n",
    "ggplot(data=dfROC,aes(x=fp,y=tp))+geom_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva ROC sale tan escalonada porque tenemos pocas muestras. Vamos a probar con un dataset más grande:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_big<-read.csv(\"data/radar.csv\", stringsAsFactors = T)\n",
    "radar_big$tipo<-relevel(radar_big$tipo,ref=\"ruido\")\n",
    "\n",
    "set.seed(123)\n",
    "itrain<-sample(1:nrow(radar_big),round(nrow(radar_big)*0.7))\n",
    "radar_big.train<- radar_big[itrain,]\n",
    "radar_big.test <- radar_big[-itrain,]\n",
    "summary(radar_big.train)\n",
    "summary(radar_big.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_radar1<-glm(data=radar_big.train,formula=tipo~distancia+potencia,family=binomial(link='logit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_preds<-data.frame(pred=predict(model_radar1,radar_big.test),                     \n",
    "                     tipo_real=radar_big.test$tipo)\n",
    "\n",
    "dfROC<-data.frame(th=unique(df_preds$pred),tp=NA,fp=NA,model=\"model1\")\n",
    "dfROC<-dfROC[order(dfROC$th),]\n",
    "\n",
    "\n",
    "for (i in 1:nrow(dfROC)){\n",
    "    v<-calctp_fp(df_preds$pred,df_preds$tipo_real,th=dfROC$th[i])\n",
    "    dfROC$tp[i]<-v[\"tp\"]\n",
    "    dfROC$fp[i]<-v[\"fp\"]\n",
    "}\n",
    "ggplot(data=dfROC,aes(x=fp,y=tp))+geom_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ROCR)\n",
    "\n",
    "#p<-predict(model_radar1,radar_big.test,type=\"response\")\n",
    "p<-predict(model_radar1,radar_big.test)\n",
    "\n",
    "pr <- prediction(p, radar_big.test$tipo,  label.ordering=c(\"ruido\",\"avion\"))\n",
    "prf <- performance(pr, measure = \"tpr\", x.measure = \"fpr\")\n",
    "plot(prf, colorize=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_radar2<-glm(data=radar_big.train,formula=tipo~I(distancia^2)+\n",
    "                  potencia,family=binomial(link='logit'))\n",
    "summary(model_radar2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p<-predict(model_radar2,radar_big.test)\n",
    "pr2 <- prediction(p, radar_big.test$tipo,label.ordering=c(\"ruido\",\"avion\"))\n",
    "prf2 <- performance(pr2, measure = \"tpr\", x.measure = \"fpr\")\n",
    "\n",
    "plot(prf) \n",
    "lines(prf2@x.values[[1]], prf2@y.values[[1]], col = 'red')\n",
    "legend(0.5,0.8,c(\"tipo~distancia+potencia\",\"tipo~I(distancia^2)+potencia\"), pch=c(\"-\",\"-\"),col=c(\"black\",\"red\"), y.intersp = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf <- performance(pr, measure = \"prec\", x.measure = \"rec\", label.ordering=c(\"ruido\",\"avion\"))\n",
    "plot(prf,colorize=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC\n",
    "\n",
    "Area bajo la curva (Area Under The Curve), número entre 0 y 1 que mide como de bueno es un clasificador. \n",
    "\n",
    "Es el area bajo la curva ROC, cuando su valor es:\n",
    "* 1 significa que el clasificador es perfecto\n",
    "* 0.5 significa que la elección es tan buena como hacerla al azar\n",
    "* Menor de 0.5, significa que lo estamos haciendo peor que el azar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pauc1<-performance(pr, measure = \"auc\", label.ordering=c(\"ruido\",\"avion\"))\n",
    "pauc1@y.values[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pauc2<-performance(pr2, measure = \"auc\", label.ordering=c(\"ruido\",\"avion\"))\n",
    "pauc2@y.values[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library(pROC)\n",
    "rocobj1 <- pROC::roc(\n",
    "    radar_big.test$tipo,\n",
    "    predict(model_radar1,radar_big.test))\n",
    "\n",
    "rocobj2 <- pROC::roc(\n",
    "    radar_big.test$tipo,\n",
    "    predict(model_radar2,radar_big.test),\n",
    "    levels=c(\"ruido\",\"avion\"),direction=\"<\")\n",
    "\n",
    "\n",
    "#plot(rocobj1, print.auc = TRUE, col = \"blue\")\n",
    "#plot(rocobj2, print.auc = TRUE, col = \"green\", print.auc.y = .4, add = TRUE)\n",
    "\n",
    "pROC::ggroc(list(model1=rocobj1, model2=rocobj2), alpha = 0.5, size = 2)+ xlab(\"1-FPR\") + ylab(\"TPR\") +\n",
    "geom_abline(slope = 1 ,intercept = 1, alpha=0.5) +\n",
    "  scale_colour_manual(values = c(\"red\",  \"#0000FF\") ,name=\"Modelo\", \n",
    "                      labels=c(paste0(\"Modelo1. AUC:\",pROC::auc(rocobj1)),\n",
    "                               paste0(\"Modelo2. AUC:\",pROC::auc(rocobj2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo\n",
    "\n",
    "Este conjunto de datos contiene información sobre los resultados del tratamiento de verrugas de 90 pacientes que utilizan crioterapia.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Cryotherapy+Dataset+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryo<-read.csv('data/Cryotherapy.csv')\n",
    "cryo$sex<-factor(cryo$sex,labels=c(\"Mujer\",\"Hombre\"))\n",
    "cryo$Type<-factor(cryo$Type,labels=c(\"Común\",\"Plantar\",\"Ambas\"))\n",
    "cryo$Result_of_Treatment<-factor(cryo$Result_of_Treatment,labels=c(\"No\",\"Si\"))\n",
    "summary(cryo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(0)\n",
    "num_train=round(0.7*nrow(cryo))\n",
    "train_ind<-sample(1:nrow(cryo),size = num_train)\n",
    "\n",
    "cryo.train=cryo[train_ind,]\n",
    "cryo.test =cryo[-train_ind,]\n",
    "summary(cryo.train)\n",
    "summary(cryo.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model<-glm(data=cryo.train,formula=Result_of_Treatment~.,family=binomial())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ROCR)\n",
    "options(repr.plot.height=4,repr.plot.width=6)\n",
    "\n",
    "\n",
    "p<-predict(model,cryo.test,type=\"response\")\n",
    "\n",
    "pr <- prediction(p, cryo.test$Result_of_Treatment)\n",
    "prf <- performance(pr, measure = \"tpr\", x.measure = \"fpr\")\n",
    "plot(prf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf_auc=performance(pr, measure = \"auc\")\n",
    "paste(\"The AUC is\",prf_auc@y.values[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "stepAIC(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model<-glm(data=cryo.train,formula=Result_of_Treatment~ age + Time + Type,family=binomial())\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p<-predict(model,cryo.test,type=\"response\")\n",
    "\n",
    "pr <- prediction(p, cryo.test$Result_of_Treatment)\n",
    "prf_auc=performance(pr, measure = \"auc\")\n",
    "paste(\"The AUC is\",prf_auc@y.values[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cvfit<-glmnetUtils::cv.glmnet(Result_of_Treatment~.+age*Time*Type+I(age^2)+I(Time^2),\n",
    "                              family = \"binomial\",\n",
    "                              data=cryo.train,nfolds=10,alpha=0.2)\n",
    "plot(cvfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p<-predict(cvfit,newdata=cryo.test,s=cvfit$lambda.min)\n",
    "\n",
    "pr <- prediction(p, cryo.test$Result_of_Treatment)\n",
    "prf_auc=performance(pr, measure = \"auc\")\n",
    "paste(\"The AUC is\",prf_auc@y.values[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn rate\n",
    "\n",
    "Vamos a utilizar un dataset publicado por IBM en [kaggle](https://www.kaggle.com/blastchar/telco-customer-churn).\n",
    "\n",
    "\n",
    "En este ejemplo vamos a cargar el dataset proporcionado y ver si somos capaces de ver qué usuarios son los que corren más riesgo de irse.\n",
    "\n",
    "El conjunto de datos incluye información sobre:\n",
    "\n",
    "* Clientes que se fueron en el último mes: la columna se llama Churn\n",
    "* Servicios para los que se ha registrado cada cliente: teléfono, líneas múltiples, Internet, seguridad en línea, copia de seguridad en línea, protección de dispositivos, soporte técnico y transmisión de TV y películas\n",
    "* Información de la cuenta del cliente: cuánto tiempo han sido cliente (columna tenure), contrato, método de pago, facturación electrónica, cargos mensuales y cargos totales\n",
    "* Información demográfica sobre los clientes: sexo, rango de edad y si tienen socios y dependientes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfchurn<-read.csv(\"data/WA_Fn-UseC_-Telco-Customer-Churn.csv\", stringsAsFactors = T)\n",
    "head(dfchurn)\n",
    "str(dfchurn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfchurn$OnlineSecurity<-NULL\n",
    "dfchurn$OnlineBackup<-NULL\n",
    "dfchurn$DeviceProtection<-NULL\n",
    "dfchurn$TechSupport<-NULL\n",
    "dfchurn$StreamingTV<-NULL\n",
    "dfchurn$StreamingMovies<-NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(dfchurn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la mayor parte de las columnas son factores. Llama la atención la columna SeniorCitizen que parece numérica, veamos que valores tiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique(dfchurn$SeniorCitizen)\n",
    "table(dfchurn$SeniorCitizen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta columna debería ser un factor, mirando otra parte de la documentación vemos que:\n",
    "\n",
    " 1 = Si es senior citizen\n",
    " \n",
    " 0 = No es senior citizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfchurn$SeniorCitizen<-factor(dfchurn$SeniorCitizen,labels = c(\"No\",\"Yes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos la columna customerID porque no nos hace falta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfchurn$customerID<-NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(12)\n",
    "idx<-sample(1:nrow(dfchurn),0.7*nrow(dfchurn))\n",
    "dfchurn.train<-dfchurn[idx,]\n",
    "dfchurn.test<-dfchurn[-idx,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(dfchurn.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model<-glm(data=dfchurn.train,formula=Churn~.,family=binomial())\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ROCR)\n",
    "options(repr.plot.height=4,repr.plot.width=6)\n",
    " \n",
    "\n",
    "df_pred<-data.frame(pred=predict(model,dfchurn.test,type=\"response\"), \n",
    "                    real= dfchurn.test$Churn)\n",
    "df_pred<-na.omit(df_pred)\n",
    "\n",
    "pr <- prediction(df_pred$pred, df_pred$real)\n",
    "prf <- performance(pr, measure = \"tpr\", x.measure = \"fpr\")\n",
    "plot(prf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf_auc=performance(pr, measure = \"auc\")\n",
    "paste(\"The AUC is\",prf_auc@y.values[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repasemos la matriz de confusión:\n",
    "\n",
    "\n",
    "|.|Predecimos condición negativa|Predecimos condición positiva|\n",
    "|-|-|-|\n",
    "|Condición negativa| $M_{11}$ | $M_{12}$|\n",
    "|Condición positiva| $M_{21}$ | $M_{22}$ |\n",
    "\n",
    "**Precisión** : $\\frac{M_{22}}{M_{12}+M_{22}}$. Cuantos aciertos tengo del total de predicciones. Nos habla de **calidad**.\n",
    "\n",
    "**Exhaustividad** o **sensibilidad** (recall, true positive rate): $\\frac{M_{22}}{M_{21}+M_{22}}$. Que ratio de los aciertos positivos soy capaz de encontrar. Nos habla de **cantidad** de encuentros.\n",
    "\n",
    "**Exactitud** (Accuracy): $\\frac{M_{11}+M_{22}}{M_{11}+M_{12}+M_{21}+M_{22}}$: Cuantas predicciones correctas he hecho.\n",
    "\n",
    "**Valor-F**: $F_\\beta=(1+\\beta^2)\\frac{Precisión·Exhaustividad}{\\beta^2·Precisión+Exhaustividad}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(e1071)\n",
    "\n",
    "\n",
    "cf_m<-confusionMatrix(data=factor(predict(model,dfchurn.test,type=\"response\")>0.5,\n",
    "                                  labels=c(\"No\",\"Yes\")), \n",
    "                      reference=dfchurn.test$Churn,\n",
    "                      positive=\"Yes\")\n",
    "cf_m\n",
    "# Más información de como obtener esas figuras:\n",
    "# https://www.rdocumentation.org/packages/caret/versions/6.0-85/topics/confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"La precisión es:\",cf_m$table[2,2]/sum(cf_m$table[2,]))\n",
    "paste(\"La exhaustividad (recall, sensitivity) es:\",cf_m$table[2,2]/sum(cf_m$table[,2]))\n",
    "paste(\"La exactitud (accuracy) es:\",(cf_m$table[2,2]+cf_m$table[1,1])/sum(cf_m$table))\n",
    "\n",
    "bnt_test=binom.test(cf_m$table[2,2]+cf_m$table[1,1],sum(cf_m$table))\n",
    "paste(\"El intervalo de confianza de la exactitud es: [\",paste0(bnt_test$conf.int,collapse=\",\"),\"]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "#model<-glm(data=dfchurn.train,formula=Churn~.,family=binomial())\n",
    "\n",
    "# Nos encuentra el modelo con menor AIC\n",
    "model_optim_aic<-stepAIC(model, direction=\"both\", trace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_optim_aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El caso de PaymentMethod es bastante curioso: Hay valores para los cuales la diferencia no es estadísitcamente significativa, pero hay otros que sí.\n",
    "\n",
    "El único valor estadísticamente significativo parece que es \"Electronic check\"\n",
    "\n",
    "Dentro de esta variable categórica vamos a comprobar que valores podemos separar y cuales agrupar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels(dfchurn$PaymentMethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_payment<-table( dfchurn[c(\"Churn\",\"PaymentMethod\")])\n",
    "tbl_payment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un test chi-cuadrado para corroborar que la probabilidad de churn depende del método de pago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq.test(tbl_payment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El test estadístico nos dice que al menos un método de pago es diferente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop.table(tbl_payment,margin=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_payment<-data.frame(apply(tbl_payment,2,function(x){binom.test(x)$conf.int}))\n",
    "df_payment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos juntar todos los grupos en \"Electronic check\" y \"Otro\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfchurn$ElectronicCheck<-factor(dfchurn$PaymentMethod==\"Electronic check\",labels=c(\"No\",\"Yes\"))\n",
    "dfchurn.train<-dfchurn[idx,]\n",
    "dfchurn.test<-dfchurn[-idx,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2<-glm(formula = Churn ~ SeniorCitizen + Dependents + tenure + MultipleLines + \n",
    "    InternetService + Contract + PaperlessBilling + ElectronicCheck + \n",
    "    TotalCharges, family = binomial(), data = dfchurn.train)\n",
    "summary(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_m2<-confusionMatrix(factor(predict(model2,dfchurn.test,type=\"response\")>0.5,\n",
    "                             labels=c(\"No\",\"Yes\")), \n",
    "                      dfchurn.test$Churn,positive=\"Yes\")\n",
    "cf_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"La precisión es:\",cf_m$table[2,2]/sum(cf_m$table[2,]))\n",
    "paste(\"La exhaustividad (recall, sensitivity) es:\",cf_m$table[2,2]/sum(cf_m$table[,2]))\n",
    "paste(\"La exactitud (accuracy) es:\",(cf_m$table[2,2]+cf_m$table[1,1])/sum(cf_m$table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_pred<-data.frame(pred=predict(model2,dfchurn.test,type=\"response\"), \n",
    "                    real= dfchurn.test$Churn)\n",
    "df_pred<-na.omit(df_pred)\n",
    "\n",
    "prf_auc=performance(pr, measure = \"auc\")\n",
    "paste(\"The AUC is\",prf_auc@y.values[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_m$table\n",
    "cf_m2$table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede profundizar más en estos datos mirando el notebook:\n",
    "\n",
    "https://www.kaggle.com/farazrahman/telco-customer-churn-logisticregression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis matriz confusión test SARS-Covid-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente imagen tenemos el prospecto de un test covid:\n",
    "\n",
    "![](img/test_covid.jpg)\n",
    "\n",
    "\n",
    "|.|Resultado PCR +|Resultado PCR -| Total |\n",
    "|-|-|-|-|\n",
    "|Test antígenos +| 425|1|426|\n",
    "|Test antígenos -| 10| 627|637|\n",
    "|Total|435|628|1063|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repasemos la matriz de confusión:\n",
    "\n",
    "\n",
    "|.|Predecimos condición negativa|Predecimos condición positiva|\n",
    "|-|-|-|\n",
    "|Condición negativa| $M_{11}$ | $M_{12}$|\n",
    "|Condición positiva| $M_{21}$ | $M_{22}$ |\n",
    "\n",
    "**Precisión** : $\\frac{M_{22}}{M_{12}+M_{22}}$. Cuantos aciertos tengo del total de predicciones. Nos habla de **calidad**.\n",
    "\n",
    "**Exhaustividad** (recall, true positive rate): $\\frac{M_{22}}{M_{21}+M_{22}}$. Que ratio de los aciertos positivos soy capaz de encontrar. Nos habla de **cantidad** de encuentros.\n",
    "\n",
    "**Exactitud** (Accuracy): $\\frac{M_{11}+M_{22}}{M_{11}+M_{12}+M_{21}+M_{22}}$: Cuantas predicciones correctas he hecho.\n",
    "\n",
    "**Valor-F**: $F_\\beta=(1+\\beta^2)\\frac{Precisión·Exhaustividad}{\\beta^2·Precisión+Exhaustividad}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M <- matrix(c(425,1,10,627),ncol=2, byrow = TRUE)\n",
    "colnames(M)<-c('pos','neg')\n",
    "rownames(M)<-c('pos','neg')\n",
    "caret::confusionMatrix(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPA (positive percent agreement)\n",
    "paste(\"Sensibilidad (PPA):\", 425/(425+10)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NPA (negative percent agreement)\n",
    "paste(\"Especificidad (NPA):\", 627/(627+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En el test lo llaman precisión pero nosotros lo hemos llamado exactitud\n",
    "# https://es.wikipedia.org/wiki/Precisi%C3%B3n_y_exactitud#En_clasificaci%C3%B3n_binaria\n",
    "# OPA (Overall Percent Agreement)\n",
    "paste(\"Exactitud (OPA):\",(425+627)/1063*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.test(425+627,1063)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive Prediction Value (PPV)\n",
    "paste(\"Precisión test positivo:\",425/(425+1)*100)\n",
    "\n",
    "#Negative Prediction Value (PPV)\n",
    "paste(\"Precisión test negativo:\",627/(627+10)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo**\n",
    "\n",
    "Si doy positivo en el test, ¿cual es la probabilidad de que realmente esté enfermo?\n",
    "\n",
    "Por simplicidad (https://xkcd.com/2587/) vamos a suponer que el test PCR de la matriz de confusión tiene una fiabilidad del 100%.\n",
    "\n",
    "Así pues la matriz de confusión la renombraríamos así:\n",
    "\n",
    "|.|COVID|Sano| Total |\n",
    "|-|-|-|-|\n",
    "|test+| 425|1|426|\n",
    "|test-| 10| 627|637|\n",
    "|Total|435|628|1063|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos están preguntando: Pr(COVID|test+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando Bayes:\n",
    "\\\\[\n",
    "Pr(COVID|test+)=\\frac{ Pr(test+|COVID)·Pr(COVID)}{Pr(test+)}\n",
    "\\\\]\n",
    "\n",
    "Pero desconocemos $P(test+)$, aunque podemos obtenerlo mediante:\n",
    "\\\\[\n",
    "\\begin{split}\n",
    "Pr(test+)&=Pr(test+,COVID)+Pr(test+,sano) \\\\\n",
    "Pr(test+)&=Pr(test+|COVID)·Pr(COVID)+Pr(test+|sano)·Pr(sano) \\\\\n",
    "\\end{split}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero sabemos que:\n",
    "* Sensibilidad (PPA) = Pr(test+|COVID) = 425/(425+10) = 97.7%\n",
    "* Probabilidad de falso positivo (False Positive Rate) = Pr(test+|sano) = 1/(627+1) = 0.16%\n",
    "* Incidencia acumulada = Pr(COVID) = 500/100.000 = 0.5%\n",
    "* Pr(sano) = 1-Pr(COVID) = 99.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_testOK_covid = M[1,1]/sum(M[,1])\n",
    "p_testOK_sano = M[1,2]/sum(M[,2])\n",
    "p_covid = 500/100000\n",
    "p_sano = 1-p_covid\n",
    "\n",
    "p_testOK = p_testOK_covid*p_covid+p_testOK_sano*p_sano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_covid_testOK = p_testOK_covid*p_covid/p_testOK\n",
    "p_covid_testOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"La probabilidad de tener COVID si el test es positivo es del \",round(p_covid_testOK*100,2),\"%\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la probabilidad de COVID en la vida real fuera la misma la que hay en el estudio, entonces tendríamos que Pr(COVID|test+) es la Precisión test positivo que calculamos antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_covid = 435/1063\n",
    "p_testOK = p_testOK_covid*p_covid+p_testOK_sano*p_sano\n",
    "p_covid_testOK = p_testOK_covid*p_covid/p_testOK\n",
    "p_covid_testOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso:\n",
    "\n",
    "Pr(COVID|test+) = Pr(test+|COVID)\n",
    "\n",
    "Porque:\n",
    "\\\\[\n",
    "Pr(COVID) = Pr(test+|COVID)·Pr(COVID)+Pr(test+|sano)·Pr(sano)\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
