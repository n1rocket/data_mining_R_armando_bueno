{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de discrimante lineal\n",
    "\n",
    "\n",
    "En 1936, Fisher formuló su teoría para el discriminate lineal (Lineal discriminant) el cual tiene muchas utilidades como clasificador.\n",
    "\n",
    "Su concepto es similar al del PCA en el cual trata de realizar una reducción de similaridad, pero mientras el PCA es un aprendizaje **no supervisado** el LDA es **supervisado**. Utilizando esta información buscaremos la proyección que mejor nos permita separar las dos clases de interés.\n",
    "\n",
    "![](img/proyeccion.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height=4,repr.plot.width=6,repr.plot.res = 300)\n",
    "\n",
    "\n",
    "set.seed(123)\n",
    "N<-100\n",
    "x1<-rnorm(N,mean=0,sd=1.5)\n",
    "x2<-x1*2+rnorm(N,mean=0,sd=1)\n",
    "dfa<-data.frame(group=\"A\",x1=x1,x2=x2, stringsAsFactors = T)\n",
    "\n",
    "x1<-rnorm(N,mean=1.5,sd=1)\n",
    "x2<-x1*2+rnorm(N,mean=4,sd=2)\n",
    "dfb<-data.frame(group=\"B\",x1=x1,x2=x2, stringsAsFactors = T)\n",
    "\n",
    "df<-data.frame(rbind(dfa,dfb))\n",
    "options(repr.plot.height=4,repr.plot.width=8)\n",
    "library(ggplot2)\n",
    "ggplot(df,aes(x=x1,y=x2,color=group))+geom_point(size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w<-matrix(c(0.001,1),nrow = 2)\n",
    "w<-w/sqrt(sum(w^2))\n",
    "\n",
    "g1<-ggplot(df,aes(x=x1,y=x2,color=group))+geom_point(size=0.1)+geom_abline(slope=w[2]/w[1])\n",
    "df$projection<-as.matrix(df[,2:3]) %*% w\n",
    "g2<-ggplot(df,aes(x=projection,color=group))+geom_density()\n",
    "\n",
    "library(ggpubr)\n",
    "ggarrange(g1,g2,ncol = 2)\n",
    "library(ROCR)\n",
    "\n",
    "pr <- prediction(df$projection, df$group)\n",
    "prf_auc=performance(pr, measure = \"auc\")\n",
    "paste(\"The AUC is\",prf_auc@y.values[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos que tenemos dos clases y un vector sobre el que proyectaremos las dos clases, de tal forma que podamos resumir el valor de cada muestra en una sola dimensión. \n",
    "\\\\[\n",
    "\\vec y = X · \\vec{w}\n",
    "\\\\]\n",
    "Donde\n",
    "* X son los datos que queremos clasificar $X \\in \\mathbb{R}^{N\\times p}$\n",
    "* v es el vector de proyección, $w \\in \\mathbb{R}^{p\\times1}$\n",
    "* y son los datos proyectados, $y \\in \\mathbb{R}^{N\\times1}$\n",
    "\n",
    "Si, sobre el valor de $y$ definimos un umbral $th_0$ tal que si $y \\geq th_0$ pertenece a una clase y si no a la otra. La elección del umbral y del vector $\\vec w$ determinarán la calidad del decisor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una posible idea sería seleccionar un vector $w$ tal que:\n",
    "\\\\[    \n",
    "\\vec w \\propto (\\vec m_B- \\vec m_A) \n",
    "\\\\]\n",
    "Donde:\n",
    "\\\\[\n",
    "\\vec m_n=\\frac{1}{N_n}\\sum_{n \\in C_n}{\\vec{x_n}}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mA<-as.matrix(colMeans(subset(df,group==\"A\")[,c(\"x1\",\"x2\")]))\n",
    "mB<-as.matrix(colMeans(subset(df,group==\"B\")[,c(\"x1\",\"x2\")]))\n",
    "w <- mB-mA\n",
    "w <- w/sum(w^2)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1<-ggplot(df,aes(x=x1,y=x2,color=group))+geom_point(size=0.1)+geom_abline(slope=w[2]/w[1])\n",
    "df$projection<-as.matrix(df[,2:3]) %*% w\n",
    "g2<-ggplot(df,aes(x=projection,color=group))+geom_density()\n",
    "ggarrange(g1,g2,ncol = 2)\n",
    "\n",
    "pr <- prediction(df$projection, df$group)\n",
    "prf_auc=performance(pr, measure = \"auc\")\n",
    "paste(\"The AUC is\",prf_auc@y.values[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta, aunque es una solución aparentemente buena no es el óptimo. Fisher lo que busca es el máximo del cociente:\n",
    "\\\\[\n",
    "    J(w)=\\frac{\\sigma_{entre ~ clases}}{\\sigma_{dentro ~ clases}} = \\frac{m_B-m_A}{\\sigma_{A proyectado}^2+\\sigma_{Bproyectado}^2}=\\frac{\\vec w^T S_{between} \\vec w}{\\vec w^T S_{within} \\vec w}\n",
    "\\\\]\n",
    "Donde $S_{between}$ es la varianza que hay entre clases:\n",
    "\\\\[\n",
    "S_{between} = (\\vec m_B - \\vec m_A)(\\vec m_B - \\vec m_A)^T\n",
    "\\\\]\n",
    "Recordemos la fórmula de la covarianza entre dos grupos $x$ e $y$ del módulo de estadística:\n",
    "\\\\[\n",
    "cov(X,Y) = \\frac{1}{N} \\sum _{i=1}^N \\left( x_i-\\bar{x} \\right)\\left( y_i-\\bar{y} \\right)\n",
    "\\\\]\n",
    "Donde $S_{within}$ es la suma de las varianzas de cada grupo:\n",
    "\\\\[\n",
    "S_{within} = \\sum_{n \\in C_A} (\\vec x_n - m_A)(\\vec x_n - m_A)^T + \\sum_{n \\in C_B} (\\vec x_n - m_B)(\\vec x_n - m_B)^T\n",
    "\\\\]\n",
    "El mínimo de la función $J(w)$ aparece para un $\\vec w$ proporcional a:\n",
    "\\\\[\n",
    "\\vec w \\propto S_{within}^{-1}(\\vec m_B- \\vec m_A) \n",
    "\\\\]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mA<-as.matrix(colMeans(subset(df,group==\"A\")[,c(\"x1\",\"x2\")]))\n",
    "mB<-as.matrix(colMeans(subset(df,group==\"B\")[,c(\"x1\",\"x2\")]))\n",
    "\n",
    "xA<-t(as.matrix(subset(df,group==\"A\")[,c(\"x1\",\"x2\")]))\n",
    "xB<-t(as.matrix(subset(df,group==\"B\")[,c(\"x1\",\"x2\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mA_rep<-matrix(rep(mA,each=ncol(xA)), ncol=ncol(xA), byrow=TRUE)\n",
    "mB_rep<-matrix(rep(mB,each=ncol(xB)), ncol=ncol(xB), byrow=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sw<-(xA-mA_rep) %*% t(xA-mA_rep)+(xB-mB_rep) %*% t(xB-mB_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w<-solve(Sw) %*% (mB-mA)\n",
    "w<-w/sqrt(sum(w^2))\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1<-ggplot(df,aes(x=x1,y=x2,color=group))+geom_point(size=0.1)+geom_abline(slope=w[2]/w[1])\n",
    "df$projection<-as.matrix(df[,2:3]) %*% w\n",
    "g2<-ggplot(df,aes(x=projection,color=group))+geom_density()\n",
    "\n",
    "ggarrange(g1,g2,ncol = 2)\n",
    "pr <- prediction(df$projection, df$group)\n",
    "prf_auc=performance(pr, measure = \"auc\")\n",
    "paste(\"The AUC is\",prf_auc@y.values[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En R tenemos la función *lda()* del paquete MASS que nos permite hacer esto mismo de una forma más sencilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "l<-lda(group~x1+x2,data=df)\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos dan el mismo resultado que teníamos antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l$scaling/sqrt(sum(l$scaling^2))\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define un umbral para clasificar la clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mA+mB)/2\n",
    "l$scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th<-c(t(l$scaling) %*% (mA+mB)/2)\n",
    "th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver la proyección y la clase clasificada con predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict(l,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict(l,df)$x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de la función predict() sobre el modelo lda es equivalente a:\n",
    "\\\\[\n",
    "X · \\vec w - \\vec w^T ·(\\vec m_B + \\vec m_A)/2\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(data.frame(\n",
    "    multiplicacion=unname(\n",
    "     as.matrix(df[,2:3]) %*% l$scaling),\n",
    "    multiplicacion_th=unname(\n",
    "        as.matrix(df[,2:3]) %*% l$scaling-th),\n",
    "    predict=unname(\n",
    "        predict(l,df)$x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La media de los residuos es 0:\n",
    "sum(as.matrix(df[,2:3]) %*% l$scaling-th-predict(l,df)$x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación con regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_glm<-glm(group~x1+x2,data=df,family=binomial)\n",
    "model_glm\n",
    "betalg<-model_glm$coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que significaban estos coeficientes:\n",
    "\\\\[\n",
    "log\\left( \\frac{p_A}{p_B} \\right) = \\beta_0+\\beta_1·x_1+\\beta_2·x2   \n",
    "\\\\]\n",
    "\n",
    "El umbral de decisión de una clase u otra lo tenemos en:\n",
    "\\\\[\n",
    "0 = \\beta_0+\\beta_1·x_1+\\beta_2·x2 \\\\\n",
    "\\beta_2·x2= -\\beta_0-\\beta_1·x_1 \\\\\n",
    "x2= -\\frac{\\beta_0}{\\beta_2}-\\frac{\\beta_1}{\\beta_2}x_1\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1<-ggplot(df,aes(x=x1,y=x2,color=group))+geom_point(size=0.1)+geom_abline(slope=w[2]/w[1])+\n",
    "geom_abline(intercept = -betalg[1]/betalg[3],slope = -betalg[2]/betalg[3], color=\"blue\" )    \n",
    "g1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque no lo parezca por la perspectiva de la gráfica, ambas rectas son orgonales. El vector que define la pendiente de la curva dada por $\\beta$ es el mismo que el vector $\\vec w$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_glm$coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b<-model_glm$coefficients[c(\"x1\",\"x2\")]\n",
    "b<-b/sqrt(sum(b^2))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](#https://media2.giphy.com/media/Z5HVfEvnxr67u/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glm<-df\n",
    "df_glm$pred<-predict(model_glm,df)\n",
    "\n",
    "g1<-ggplot(df_glm,aes(x=pred,color=group))+geom_density()+ggtitle(\"GLM\")\n",
    "df$projection<-as.matrix(df[,2:3]) %*% w#l$scaling# w\n",
    "#df$projection<-predict(l,df)$x+th\n",
    "g2<-ggplot(df,aes(x=projection,color=group))+geom_density()+ggtitle(\"LDA\")\n",
    "\n",
    "ggarrange(g1,g2,ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo Iris\n",
    "\n",
    "Vamos a utilizar el dataset Iris para ver si somos capaces de diferenciar una clase del resto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx<-sample(1:nrow(iris),nrow(iris)*0.7)\n",
    "iris_train<-iris[idx,]\n",
    "iris_test<-iris[-idx,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forma manual**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_class<-'virginica'\n",
    "X<-iris_train[,1:4]\n",
    "X<-as.matrix(X)\n",
    "y<-as.matrix(ifelse(iris_train$Species==iris_class,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mA<-colMeans(X[y==1,])\n",
    "mB<-colMeans(X[y==0,])\n",
    "\n",
    "xA<-t(X[y==1,])\n",
    "xB<-t(X[y==0,])\n",
    "      \n",
    "mA_rep<-matrix(rep(mA,each=ncol(xA)), ncol=ncol(xA), byrow=TRUE)\n",
    "mB_rep<-matrix(rep(mB,each=ncol(xB)), ncol=ncol(xB), byrow=TRUE)\n",
    "\n",
    "Sw<-(xA-mA_rep) %*% t(xA-mA_rep)+(xB-mB_rep) %*% t(xB-mB_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w<-solve(Sw) %*% (mB-mA)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test<-iris_test[,1:4]\n",
    "X_test<-as.matrix(X_test)\n",
    "y_test<-as.matrix(ifelse(iris_test$Species==iris_class,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.frame(projection=X_test %*% w,group=factor(y_test))\n",
    "ggplot(df,aes(x=projection,color=group))+geom_density()+ggtitle(\"LDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usando función de R**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_class<-'virginica'\n",
    "iris_train$class<-(ifelse(iris_train$Species==iris_class,1,0))\n",
    "iris_test$class<-(ifelse(iris_test$Species==iris_class,1,0))\n",
    "summary(iris_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l<-lda(class~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,data=iris_train)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l$scaling/sqrt(sum(l$scaling^2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w/sqrt(sum(w^2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.frame(projection=unname(predict(l,iris_test)$x),group=factor(iris_test$class))\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ggplot(df,aes(x=projection,color=group))+geom_density()+ggtitle(\"LDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA para clases múltiples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos que tenemos dos clases y un vector sobre el que proyectaremos las dos clases, de tal forma que podamos resumir el valor de cada muestra en una sola dimensión. \n",
    "\\\\[\n",
    "\\vec y = X · \\vec{w}\n",
    "\\\\]\n",
    "Donde\n",
    "* X son los datos que queremos clasificar $X \\in \\mathbb{R}^{N\\times p}$\n",
    "* w es el vector de proyección, $w \\in \\mathbb{R}^{p\\times1}$\n",
    "* y son los datos proyectados, $y \\in \\mathbb{R}^{N\\times1}$\n",
    "\n",
    "Podemos generalizar a $K$ clases el problema suponiendo que $y$ tiene más columnas, una por cada clase que queremos clasificar:\n",
    "\\\\[\n",
    "\\vec y_k = X · \\vec{w_k}\n",
    "\\\\]\n",
    "* $w_k$ es el vector de proyección, $w \\in \\mathbb{R}^{p\\times1}$ que diferencia la clase $k$ del resto\n",
    "* $y_k$ son los datos proyectados que maximizan la separación entre la clase $k$ y el resto, $y_k \\in \\mathbb{R}^{N\\times1}$\n",
    "\n",
    "Podemos crear la matrix $Y$ combinando todas las $y_k$:\n",
    "\\\\[\n",
    "\\vec Y = X · W\n",
    "\\\\]\n",
    "* $W$ es la matriz de proyección, $w \\in \\mathbb{R}^{p\\times K}$\n",
    "* $Y$ son los datos proyectados de tal forma que cada columa $k$ maximiza la separación entre la clase $k$ y el resto, $Y \\in \\mathbb{R}^{N\\times K}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que Fisher lo que busca es el máximo del cociente:\n",
    "\\\\[\n",
    "    J(w)=\\frac{\\sigma_{entre ~ clases}}{\\sigma_{dentro ~ clases}} =\\frac{ |\\vec w^T S_{between} \\vec w|}{|\\vec w^T S_{within} \\vec w |}  = Tr \\left\\{ \\left( \\vec w^T S_{within} \\vec w \\right)^{-1} \\left( \\vec w^T S_{between} \\vec w \\right) \\right\\}\n",
    "\\\\]\n",
    "\n",
    "Definimos la media global y para cada clase:\n",
    "\\\\[\n",
    "\\vec \\mu= \\frac{1}{N}\\sum_{i\\in N} x_i ~~~~~~~~~ \\vec \\mu \\in \\mathbb{R}^{p\\times 1}\\\\\n",
    "\\vec \\mu_k= \\frac{1}{N_k}\\sum_{i\\in C_k} x_i  ~~~~~~~~~  \\vec \\mu_k \\in \\mathbb{R}^{p\\times 1}\n",
    "\\\\]\n",
    "\n",
    "Donde $S_{between}$ es la varianza que hay entre clases. Como se separa cada clase de la media global.\n",
    "\n",
    "Para dos clases era:\n",
    "\\\\[\n",
    "S_{between} = (\\vec m_B - \\vec m_A)(\\vec m_B - \\vec m_A)^T\n",
    "\\\\]\n",
    "La generalización para K clases es:\n",
    "\\\\[\n",
    "S_{between} = \\sum_{k=1}^K N_k (\\vec \\mu_k - \\vec \\mu)(\\vec \\mu_k - \\vec \\mu)^T ~~~~~~~~~ S_{between} \\in \\mathbb{R}^{p\\times p}\\\\\n",
    "\\\\]\n",
    "\n",
    "\n",
    "Donde $S_{within}$ es la suma de las varianzas de cada grupo. Como varían las muestras dentro de cada clase:\n",
    "\n",
    "Para dos clases era:\n",
    "\\\\[\n",
    "S_{within} = \\sum_{n \\in C_A} (\\vec x_n - m_A)(\\vec x_n - m_A)^T + \\sum_{n \\in C_B} (\\vec x_n - m_B)(\\vec x_n - m_B)^T\n",
    "\\\\]\n",
    "La generalización para K clases es:\n",
    "\\\\[\n",
    "S_{within} = \\sum_{k=1}^K \\sum_{i\\in C_k} (\\vec x_i - \\vec \\mu_k)(\\vec x_i - \\vec \\mu_k)^T ~~~~~~~~~\\vec x_i \\in \\mathbb{R}^{p\\times 1} ~~~  S_{within} \\in \\mathbb{R}^{p\\times p}\\\\\n",
    "\\\\]\n",
    "\n",
    "El máximo de J(w) se consigue cuando:\n",
    "\\\\[\n",
    "S_{between}·W = \\lambda S_{within} · W \\\\\n",
    " S_{within}^{-1} S_{between} W = \\lambda W\n",
    "\\\\]\n",
    "La solución viene dada por los autovectores, de cuyos K-1 autovalores son mayores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx<-sample(1:nrow(iris),nrow(iris)*0.7)\n",
    "iris_train<-iris[idx,]\n",
    "iris_test<-iris[-idx,]\n",
    "\n",
    "X<-iris_train[,1:4]\n",
    "X<-as.matrix(X)\n",
    "Cl<-iris_train$Species\n",
    "p<-ncol(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(Cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu<-colMeans(X)\n",
    "Sb=matrix(0L, nrow = p, ncol = p) \n",
    "for (k in levels(Cl)){\n",
    "    mu_k=colMeans(X[Cl==k,])\n",
    "    N_k=sum(Cl==k)\n",
    "    Sb=Sb+N_k*(mu_k-mu) %*% t(mu_k-mu)\n",
    "}\n",
    "Sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sw<-matrix(0L, nrow=p, ncol=p)\n",
    "for (k in levels(Cl)){\n",
    "    X_k<-X[Cl==k,]\n",
    "    mu_k=colMeans(X[Cl==k,])\n",
    "    for (i in 1:nrow(X_k)){\n",
    "        X_i<-as.matrix(X_k[i,])        \n",
    "        Sw<-Sw+(X_i-mu_k) %*% t(X_i-mu_k)\n",
    "    }\n",
    "}\n",
    "Sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se puede calcular Sw de una forma más eficiente pensando :\n",
    "\n",
    "Sw<-matrix(0L, nrow=p, ncol=p)\n",
    "for (k in levels(Cl)){\n",
    "    X_k<-X[Cl==k,]\n",
    "    mu_k=colMeans(X[Cl==k,])\n",
    "    \n",
    "    mu_krep<-matrix(rep(mu_k,each=nrow(X_k)), ncol=nrow(X_k), byrow=TRUE)\n",
    "    X_k<-t(as.matrix(X_k))\n",
    "    Sw<-Sw+(X_k-mu_krep) %*% t(X_k-mu_krep)\n",
    "    \n",
    "}\n",
    "Sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(solve(Sw) %*% Sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig<-eigen(solve(Sw) %*% Sb)\n",
    "eig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realmente la proyección óptima debería ser sobre K-1, es decir 2 columnas. \n",
    "Con los dos primeros autovectores podríamos definir bien las fronteras de las 3 clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W<-Re(eig$vectors[,1:2])\n",
    "W\n",
    "head(X %*% W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "l<-lda(formula=Species ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data=iris_train)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W\n",
    "l$scaling / sqrt(colSums(l$scaling^2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W<-eig$vectors[,1:2]\n",
    "iris_train[,c(\"projX1\",\"projX2\")]<-Re(X %*% W)\n",
    "ggplot(iris_train,aes(x=projX1,y=projX2,color=Species))+geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, el mayor poder discriminante se encuenta en la primera proyección que es la que corresponde al autovalor más grande. Esto tiene sentido porque el primer autovector es 100 veces más grande que el segundo. Esto indica que la primera dimensión tiene casi todo el poder discriminante.\n",
    "\n",
    "Podemos comprobarlo proyectando solo sobre el primer discrimante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W<-eig$vectors[,1]\n",
    "iris_train$projection <- Re(X %*% W)\n",
    "ggplot(iris_train,aes(x=projection,color=Species))+geom_density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el conjunto de training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test<-as.matrix(iris_test[,1:4])\n",
    "iris_test$projection <- Re(X_test %*% W)\n",
    "ggplot(iris_test,aes(x=projection,color=Species))+geom_density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_iris<-predict(l,iris_train)\n",
    "df_ld_iris<-data.frame(ld_iris$x)\n",
    "df_ld_iris$Species<-iris_train$Species\n",
    "ggplot(df_ld_iris,aes(x=-LD1,y=LD2,color=Species))+geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_iris <- predict(l,iris_test)\n",
    "pred_test_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(real=iris_test$Species, pred=pred_test_iris$class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_m<-caret::confusionMatrix(data=pred_test_iris$class, reference=iris_test$Species)\n",
    "cf_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.rdocumentation.org/packages/caret/versions/6.0-85/topics/confusionMatrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"La exhaustividad (recall, sensitivity) para Setosa:\",cf_m$table[1,1]/sum(cf_m$table[,1]))\n",
    "paste(\"La exhaustividad (recall, sensitivity) para Versicolor:\",cf_m$table[2,2]/sum(cf_m$table[,2]))\n",
    "paste(\"La exhaustividad (recall, sensitivity) para Virginica:\",cf_m$table[3,3]/sum(cf_m$table[,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"La precisión (Pos Pred Value) para Setosa:\",cf_m$table[1,1]/sum(cf_m$table[1,]))\n",
    "paste(\"La precisión (Pos Pred Value) para Versicolor:\",cf_m$table[2,2]/sum(cf_m$table[2,]))\n",
    "paste(\"La precisión (Pos Pred Value) para Virginica:\",cf_m$table[3,3]/sum(cf_m$table[3,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación con PCA\n",
    "\n",
    "En PCA también podíamos reducir dimensionalidad, pero al ser agnóstico a la clasificación, no lo hace tan bien cuando tratamos de diferenciar clases etiquetadas a priori:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prmydata<-prcomp(X)\n",
    "prmydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_train[,c(\"PC1\",\"PC2\")] <- predict(prmydata,newdata = iris_train[,1:4])[,1:2]\n",
    "\n",
    "ggplot(iris_train,aes(x=PC1,y=PC2,color=Species))+geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Información de como repetir este mismo ejercicio en Python:\n",
    "https://sebastianraschka.com/Articles/2014_python_lda.html#step-5-transforming-the-samples-onto-the-new-subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
